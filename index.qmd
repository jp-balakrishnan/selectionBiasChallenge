---
title: "Selection Bias & Missing Data Challenge"
subtitle: "Creating a Statistics Meme: Write Your Own Functions"
format:
  html: default
execute:
  echo: false
  eval: true
---

# ðŸŽ¨ Selection Bias & Missing Data Challenge

::: {.callout-important}
## ðŸ“Š Challenge Overview

Create a four-panel statistics meme demonstrating selection bias. You'll write three Python functions yourself to complete the workflow, then assemble them into a professional meme.

:::

```{python}
#| label: final-meme
#| echo: false
#| eval: true
#| fig-cap: "Statistics meme demonstrating selection bias"

import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from step1_prepare_image import prepare_image

# Load and prepare the image
img_path = 'ai_father.jpg'  # Example image - replace with your own image
gray_image = prepare_image(img_path, max_size=512)

from step2_create_stipple import create_stipple

# Create stippled image
stipple_pattern, samples = create_stipple(
    gray_image,
    percentage=0.08,  # 8% of pixels will be stippled
    sigma=0.9,  # Repulsion radius
    content_bias=0.9,  # Strongly follow importance map
    noise_scale_factor=0.1,  # Moderate exploration
    extreme_downweight=0.5,  # Moderate downweighting of extremes
    extreme_threshold_low=0.2,  # Downweight tones below 0.2
    extreme_threshold_high=0.8,  # Downweight tones above 0.8
    extreme_sigma=0.1  # Smooth transition width
)

from step4_create_block_letter import create_block_letter_g
 
# Get image dimensions
h, w = gray_image.shape
 
# Create block letter A
block_letter = create_block_letter_g(h, w, letter="G", font_size_ratio=0.9)

from step5_create_masked import create_masked_stipple
 
# Create masked stippled image
masked_stipple = create_masked_stipple(
    stipple_pattern,
    block_letter,
    threshold=0.5  # Pixels below 0.5 are considered part of the mask
)

from create_meme import create_statistics_meme

# Create the final meme
create_statistics_meme(
    original_img=gray_image,
    stipple_img=stipple_pattern,
    block_letter_img=block_letter,
    masked_stipple_img=masked_stipple,
    output_path="my_statistics_meme.png",
    dpi=150,
    background_color="white"  # or "pink", "lightgray", etc.
)

# Display the final meme
from IPython.display import Image, display
display(Image("my_statistics_meme.png"))


```


### Explanation

This statistics meme provides a powerful visual demonstration of **selection bias** and its impact on statistical inference. The four-panel visualization walks through the progression from truth to biased estimate, making abstract statistical concepts tangible through image processing.

The first panel (**Reality**) represents the **true population**â€”the complete, unbiased ground truth containing all information about the subject. The second panel (**Your Sample**) shows the stippled (dot-pattern) version, representing our **data collection process**â€”a sample of observations that, when properly collected, should still represent the underlying reality through strategic placement of data points. The third panel (**Selection Bias**) features the bold letter "G", representing a **systematic, non-random pattern of missing data**â€”specifically **MNAR (Missing Not At Random)**, where missingness depends on unobserved data characteristics. The final panel (**Estimate**) reveals the **biased estimate**: the white "G"-shaped void cuts through the stippled image, creating a systematic gap that distorts our view. Critical information within the "G" region is absent, and this distorted view no longer accurately represents the true population.

This visualization demonstrates a fundamental problem in statistics: when data is missing in a systematic pattern (MNAR), standard methods assuming random missingness produce **biased estimates**. The systematic exclusion creates a non-representative sample, leading to incorrect conclusions. Just as the "G"-shaped gap distorts our visual understanding, selection bias distorts our statistical understanding of populations in real research. This mirrors countless real-world scenarios: non-response bias in surveys, attrition bias in longitudinal studies, publication bias favoring significant results, and volunteer bias where participants differ systematically from the population.

The key takeaway is that **recognizing selection bias is the first step toward addressing it**. Through careful study design, appropriate statistical methods (e.g., inverse probability weighting, propensity score matching), sensitivity analyses, and transparent reporting of limitations, researchers can mitigate the impact of selection bias and draw more valid conclusions from their data.

